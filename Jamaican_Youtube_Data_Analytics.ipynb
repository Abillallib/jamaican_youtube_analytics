{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Aim**"
      ],
      "metadata": {
        "id": "8Lo2XT6tFKG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To analyze Jamaican-related content on YouTube in order to identify the categories, creators, and themes that resonate most with viewers, and to track how interest in Jamaican content has evolved over time. This analysis will provide actionable insights for content creators (including yourself) to better align with audience preferences.\n",
        "\n"
      ],
      "metadata": {
        "id": "LNsDP1mgFNE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "What types of Jamaican-related content resonate most with audiences on YouTube (in terms of views, likes, comments, engagement)?\n",
        "\n",
        "How has Jamaican YouTube content evolved over the last 5 years (2019‚Äì2024) across themes such as music, food, politics, sports, and travel?\n",
        "\n",
        "What role do Jamaican creators vs. non-Jamaican creators play in shaping content about Jamaica?\n",
        "\n",
        "How do audiences‚Äô interests in Jamaican content shift over time?\n",
        "\n"
      ],
      "metadata": {
        "id": "KSgqTrJFEGzg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Definition of Jamaican Content**"
      ],
      "metadata": {
        "id": "fWZkRu73FmZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "A video will be classified as Jamaican-related content if it satisfies **at least one of** the following:\n",
        "\n",
        "**Channel-based criterion**\n",
        "\n",
        "The channel country is listed as Jamaica (channel.snippet.country=\"JM\" in metadata).\n",
        "\n",
        "OR the channel is identified as owned/operated by a Jamaican creator (to be confirmed through metadata/manual checks).\n",
        "\n",
        "**Video-based criterion**\n",
        "\n",
        "The video explicitly mentions ‚ÄúJamaica‚Äù or Jamaican-related keywords in the title, description, tags, or transcript.\n",
        "\n",
        "OR the video‚Äôs subject matter is directly related to Jamaica (e.g., Jamaican food, music, sports, culture, politics).\n",
        "\n",
        "**Hybrid criterion**\n",
        "\n",
        "A video produced by a diaspora Jamaican creator (channel.snippet.country ‚â† Jamaica, but content consistently focuses on Jamaican themes).\n",
        "\n"
      ],
      "metadata": {
        "id": "BDVM2Y9hFo9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Background Requirements**"
      ],
      "metadata": {
        "id": "dA1uQ1GUFwKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**YouTube API Access:** A developer key from Google Cloud to fetch video and channel metadata.\n",
        "\n",
        "**Libraries:**\n",
        "\n",
        "google-api-python-client (fetch metadata)\n",
        "\n",
        "youtube_transcript_api (pull transcripts when available)\n",
        "\n",
        "pandas / numpy (data wrangling)\n",
        "\n",
        "isodate (parse durations)\n",
        "\n",
        "NLP/AI tools (scikit-learn, transformers or openai embeddings) for clustering/classification.\n",
        "\n",
        "**Data Scope:**\n",
        "\n",
        "~500‚Äì1000 videos initially.\n",
        "\n",
        "Videos collected using broad \"Jamaica\" keyword + channel.snippet.country=\"JM\".\n",
        "\n",
        "**Metadata timeframe:** 2019‚Äì2024 (5 years).\n",
        "\n"
      ],
      "metadata": {
        "id": "jfLK73yFFyD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Methodology**"
      ],
      "metadata": {
        "id": "4F4Fjkb1GagM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Step 1: Data Collection**\n",
        "\n",
        "Use YouTube Data API to collect video-level metadata (title, description, tags, stats, publish date, etc.) and channel-level metadata (region, subs, views, creation date).\n",
        "\n",
        "Expand scope with transcript data when available.\n",
        "\n",
        "**Step 2: Data Cleaning**\n",
        "\n",
        "Identify and filter out irrelevant videos (e.g., ‚ÄúJamaica Ave NYC‚Äù or ‚ÄúAgua de Jamaica drink‚Äù).\n",
        "\n",
        "Create a ‚ÄúTrue Jamaican Content‚Äù flag via manual labeling of a sample, then scale with simple ML classification.\n",
        "\n",
        "**Step 3: Categorization**\n",
        "\n",
        "Use a hybrid approach:\n",
        "\n",
        "Start with metadata (tags, titles, transcripts).\n",
        "\n",
        "Apply AI-assisted clustering to group content into emergent categories (e.g., music, food, travel, politics, sports).\n",
        "\n",
        "**Step 4: Analysis**\n",
        "\n",
        "Descriptive stats: Most-viewed, top-engaged, top creators, category breakdowns.\n",
        "\n",
        "Trend analysis: Category distribution by year (2019‚Äì2024).\n",
        "\n",
        "Engagement analysis: Compare engagement ratios across categories.\n",
        "\n",
        "Creator analysis: Jamaican channels vs. non-Jamaican channels producing Jamaican content.\n",
        "\n",
        "**Step 5: Visualization & Insights**\n",
        "\n",
        "Timeline of Jamaican content evolution (stacked by categories).\n",
        "\n",
        "Heatmap of engagement by theme.\n",
        "\n",
        "Top Jamaican-related creators and videos."
      ],
      "metadata": {
        "id": "7YkOQS4TGmCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Python Code**"
      ],
      "metadata": {
        "id": "9XUS4LHIHfiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 1:  Install Date Package"
      ],
      "metadata": {
        "id": "KbJNSm7dKT71"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaac4b31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf3cad0-0c15-46ad-8845-0def24c99b8f"
      },
      "source": [
        "!pip install isodate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting isodate\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate\n",
            "Successfully installed isodate-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " üîπ Step 2: Connect to the API"
      ],
      "metadata": {
        "id": "Fe08ArGPL6sg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "from googleapiclient.errors import HttpError\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "#import getpass\n",
        "import isodate\n",
        "import time\n",
        "\n",
        "# üîë Enter your YouTube API key securely (will not show in output)\n",
        "API_KEY = userdata.get('YOUTUBE_DATA_V3_KEY') #getpass.getpass(\"Enter your YouTube API Key: \")\n",
        "\n",
        "# Initialize YouTube API client\n",
        "youtube = build(\"youtube\", \"v3\", developerKey=API_KEY)\n"
      ],
      "metadata": {
        "id": "qKMqdg3mL80l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Safe API Call Wrapper"
      ],
      "metadata": {
        "id": "6sHShDpzZLH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_api_call(request, retries=3, backoff=5):\n",
        "    \"\"\"Executes a YouTube API request with retries & quota handling.\"\"\"\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            return request.execute()\n",
        "        except HttpError as e:\n",
        "            error_msg = str(e)\n",
        "            print(f\"Attempt {attempt + 1}: API Error - {error_msg}\")\n",
        "\n",
        "            if \"quotaExceeded\" in error_msg:\n",
        "                print(\"‚ùå Daily quota exceeded. Try again tomorrow.\")\n",
        "                return None\n",
        "            elif \"userRateLimitExceeded\" in error_msg or \"rateLimitExceeded\" in error_msg:\n",
        "                wait = backoff * (2 ** attempt)  # Exponential backoff\n",
        "                print(f\"‚ö† Rate limit hit. Retrying in {wait} seconds...\")\n",
        "                time.sleep(wait)\n",
        "                continue\n",
        "            elif \"badRequest\" in error_msg or \"400\" in error_msg:\n",
        "                print(\"‚ùå Bad request - check your parameters\")\n",
        "                return None\n",
        "            else:\n",
        "                print(f\"‚ùå API error: {error_msg}\")\n",
        "                return None\n",
        "\n",
        "    print(\"‚ùå Max retries exceeded\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "iR_WCwdGZOsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπStep 3: Search for channels with country=JM"
      ],
      "metadata": {
        "id": "20L3wqCGG8VP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_jamaican_channels(max_results=50, page_token=None):\n",
        "    \"\"\"Search for channels related to Jamaica\"\"\"\n",
        "    try:\n",
        "        request = youtube.search().list(\n",
        "            part=\"snippet\",\n",
        "            type=\"channel\",\n",
        "            q=\"Jamaica\",\n",
        "            maxResults=min(max_results, 50),  # API limit is 50\n",
        "            pageToken=page_token\n",
        "        )\n",
        "        response = safe_api_call(request)\n",
        "        return response.get(\"items\", []) if response else []\n",
        "    except Exception as e:\n",
        "        print(f\"Error in search_jamaican_channels: {e}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "rRyiaPL7G_DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπStep 4: Filter Channels by Country"
      ],
      "metadata": {
        "id": "pTvy3dKIJGnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_channel_metadata(channel_ids):\n",
        "    \"\"\"Get channel metadata and filter by country=JM\"\"\"\n",
        "    if not channel_ids:\n",
        "        return []\n",
        "\n",
        "    # Split into batches of 50 (API limit)\n",
        "    channels = []\n",
        "    for i in range(0, len(channel_ids), 50):\n",
        "        batch = channel_ids[i:i+50]\n",
        "\n",
        "        request = youtube.channels().list(\n",
        "            part=\"snippet,statistics,contentDetails\",\n",
        "            id=\",\".join(batch)\n",
        "        )\n",
        "        response = safe_api_call(request)\n",
        "\n",
        "        if not response:\n",
        "            continue\n",
        "\n",
        "        for item in response.get(\"items\", []):  # Fixed: added .get()\n",
        "            country = item[\"snippet\"].get(\"country\", \"Unknown\")\n",
        "            if country == \"JM\":  # ‚úÖ Jamaican channel\n",
        "                channels.append({\n",
        "                    \"id\": item[\"id\"],\n",
        "                    \"title\": item[\"snippet\"][\"title\"],\n",
        "                    \"country\": country\n",
        "                    #\"subscriber_count\": int(item[\"statistics\"].get(\"subscriberCount\", 0) or 0),\n",
        "                    #\"video_count\": int(item[\"statistics\"].get(\"videoCount\", 0) or 0)\n",
        "                })\n",
        "\n",
        "    return channels"
      ],
      "metadata": {
        "id": "PKl8iPR_JJ9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπStep 5: Fetch Uploads from Jamaican Channels"
      ],
      "metadata": {
        "id": "Sz3P8JwIHT92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_channel_uploads(channel_id, max_results=50, max_pages=8):\n",
        "    \"\"\"Get uploads from a channel's uploads playlist\"\"\"\n",
        "    try:\n",
        "        # Get the uploads playlist ID\n",
        "        request = youtube.channels().list(\n",
        "            part=\"contentDetails\",\n",
        "            id=channel_id\n",
        "        )\n",
        "        response = safe_api_call(request)\n",
        "\n",
        "        if not response or not response.get(\"items\"):\n",
        "            print(f\"No channel found for ID: {channel_id}\")\n",
        "            return []\n",
        "\n",
        "        uploads_playlist_id = response[\"items\"][0][\"contentDetails\"][\"relatedPlaylists\"][\"uploads\"]\n",
        "\n",
        "        # Fetch videos from uploads playlist\n",
        "        playlist_items = []\n",
        "        next_page = None\n",
        "        page_count = 0\n",
        "\n",
        "        while page_count < max_pages:\n",
        "            playlist_request = youtube.playlistItems().list(\n",
        "                part=\"snippet\",\n",
        "                playlistId=uploads_playlist_id,\n",
        "                maxResults=min(max_results, 50),\n",
        "                pageToken=next_page\n",
        "            )\n",
        "\n",
        "            playlist_response = safe_api_call(playlist_request)\n",
        "            if not playlist_response:\n",
        "                break\n",
        "\n",
        "            items = playlist_response.get(\"items\", [])\n",
        "            if not items:\n",
        "                break\n",
        "\n",
        "            playlist_items.extend(items)\n",
        "            next_page = playlist_response.get(\"nextPageToken\")\n",
        "            page_count += 1\n",
        "\n",
        "            if not next_page:\n",
        "                break\n",
        "\n",
        "            # Small delay to avoid rate limiting\n",
        "            time.sleep(0.1)\n",
        "\n",
        "        return playlist_items\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting uploads for channel {channel_id}: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "jeKfeIkBHWfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ Step 6: Search for Jamaican Content"
      ],
      "metadata": {
        "id": "IusCg4x1MTZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_videos(query, max_results=20, region_code=\"JM\", max_pages=90):\n",
        "    \"\"\"Search for videos with specific query\"\"\"\n",
        "    videos = []\n",
        "    next_page = None\n",
        "    page_count = 0\n",
        "\n",
        "    while page_count < max_pages:\n",
        "        try:\n",
        "            request = youtube.search().list(\n",
        "                q=query,\n",
        "                part=\"snippet\",\n",
        "                type=\"video\",\n",
        "                maxResults=min(max_results, 50),\n",
        "                regionCode=region_code,\n",
        "                pageToken=next_page,\n",
        "                publishedAfter=\"2019-01-01T00:00:00Z\"\n",
        "            )\n",
        "\n",
        "            response = safe_api_call(request)\n",
        "            if not response:\n",
        "                break\n",
        "\n",
        "            items = response.get(\"items\", [])\n",
        "            if not items:\n",
        "                break\n",
        "\n",
        "            videos.extend(items)\n",
        "            next_page = response.get(\"nextPageToken\")\n",
        "            page_count += 1\n",
        "\n",
        "            if not next_page:\n",
        "                break\n",
        "\n",
        "            time.sleep(0.1)  # Small delay\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in search_videos: {e}\")\n",
        "            break\n",
        "\n",
        "    return videos"
      ],
      "metadata": {
        "id": "j9DIf9dIMWJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπStep 7: Get Video Details"
      ],
      "metadata": {
        "id": "gjNxYqiDMYhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_details(video_ids):\n",
        "    \"\"\"Get detailed video information\"\"\"\n",
        "    if not video_ids:\n",
        "        return []\n",
        "\n",
        "    all_videos = []\n",
        "    # Process in batches of 50 (API limit)\n",
        "    for i in range(0, len(video_ids), 50):\n",
        "        batch = video_ids[i:i+50]\n",
        "\n",
        "        request = youtube.videos().list(\n",
        "            part=\"snippet,statistics,contentDetails\",\n",
        "            id=\",\".join(batch)\n",
        "        )\n",
        "        response = safe_api_call(request)\n",
        "\n",
        "        if response:\n",
        "            all_videos.extend(response.get(\"items\", []))\n",
        "\n",
        "        time.sleep(0.1)  # Small delay between requests\n",
        "\n",
        "    return all_videos"
      ],
      "metadata": {
        "id": "ZSaaZGsqMccd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " üîπ Step 8: Store Video Data into a DataFrame"
      ],
      "metadata": {
        "id": "XURatcQBMeei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_videos(video_details):\n",
        "    \"\"\"Parse video details into DataFrame format\"\"\"\n",
        "    data = []\n",
        "    for video in video_details:\n",
        "        try:\n",
        "            snippet = video[\"snippet\"]\n",
        "            stats = video.get(\"statistics\", {})\n",
        "            content = video[\"contentDetails\"]\n",
        "\n",
        "            # Parse duration safely\n",
        "            try:\n",
        "                duration = isodate.parse_duration(content[\"duration\"]).total_seconds()\n",
        "            except Exception:\n",
        "                duration = None\n",
        "\n",
        "            data.append({\n",
        "                \"video_id\": video[\"id\"],\n",
        "                \"title\": snippet[\"title\"],\n",
        "                \"description\": snippet.get(\"description\", \"\"),\n",
        "                \"tags\": \", \".join(snippet.get(\"tags\", []) or []),\n",
        "                \"channel_id\": snippet[\"channelId\"],\n",
        "                \"channel_title\": snippet[\"channelTitle\"],\n",
        "                \"publish_date\": snippet[\"publishedAt\"],\n",
        "                \"duration_seconds\": duration,\n",
        "                \"views\": int(stats.get(\"viewCount\", 0) or 0),\n",
        "                \"likes\": int(stats.get(\"likeCount\", 0) or 0),\n",
        "                \"comments\": int(stats.get(\"commentCount\", 0) or 0),\n",
        "                \"category_id\": snippet.get(\"categoryId\", \"\")\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing video {video.get('id', 'unknown')}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "nv43qLNTMgaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " üîπ Step 9: Get Channel Details"
      ],
      "metadata": {
        "id": "pC4H_aokhUxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_channel_statistics(channel_ids):\n",
        "    \"\"\"Get channel statistics with batch processing for API efficiency\"\"\"\n",
        "    if not channel_ids:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    channel_data = []\n",
        "\n",
        "    # Process in batches of 50 (API limit)\n",
        "    for i in range(0, len(channel_ids), 50):\n",
        "        batch = channel_ids[i:i+50]\n",
        "\n",
        "        request = youtube.channels().list(\n",
        "            part=\"snippet,statistics\",\n",
        "            id=\",\".join(batch)\n",
        "        )\n",
        "        response = safe_api_call(request)\n",
        "\n",
        "        if not response:\n",
        "            continue\n",
        "\n",
        "        for channel in response.get(\"items\", []):\n",
        "            snippet = channel[\"snippet\"]\n",
        "            stats = channel[\"statistics\"]\n",
        "\n",
        "            channel_data.append({\n",
        "                \"channel_id\": channel[\"id\"],\n",
        "                \"channel_start_date\": snippet[\"publishedAt\"],\n",
        "                \"channel_country\": snippet.get(\"country\", \"Unknown\"),\n",
        "                \"subscriber_count\": int(stats.get(\"subscriberCount\", 0) or 0),\n",
        "                \"channel_total_views\": int(stats.get(\"viewCount\", 0) or 0),\n",
        "                \"channel_video_count\": int(stats.get(\"videoCount\", 0) or 0)\n",
        "            })\n",
        "\n",
        "        # Small delay between batch requests\n",
        "        if i + 50 < len(channel_ids):\n",
        "            time.sleep(0.5)\n",
        "\n",
        "    return pd.DataFrame(channel_data)"
      ],
      "metadata": {
        "id": "-3EGhwdQhatP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " üîπ Step 10a: Get unique channels from video data"
      ],
      "metadata": {
        "id": "xL3jL_VOk_nN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîç Step 10a: Collecting videos from Jamaican channels...\")\n",
        "\n",
        "jamaican_channels = search_jamaican_channels(max_results=50)\n",
        "\n",
        "# Fixed channel ID extraction with better error handling\n",
        "jamaican_channel_ids = []\n",
        "for ch in jamaican_channels:\n",
        "    try:\n",
        "        if (isinstance(ch.get(\"id\"), dict) and\n",
        "            \"channelId\" in ch[\"id\"] and\n",
        "            ch[\"id\"][\"channelId\"]):\n",
        "            jamaican_channel_ids.append(ch[\"id\"][\"channelId\"])\n",
        "    except (KeyError, TypeError) as e:\n",
        "        print(f\"Skipping invalid channel entry: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Found {len(jamaican_channel_ids)} channel IDs to process\")\n",
        "\n",
        "# Filter channels by country first (more efficient)\n",
        "if jamaican_channel_ids:\n",
        "    print(\"üîç Filtering channels by country (JM)...\")\n",
        "    jamaican_channels_filtered = get_channel_metadata(jamaican_channel_ids)\n",
        "    verified_channel_ids = [ch[\"id\"] for ch in jamaican_channels_filtered]\n",
        "    print(f\"Verified {len(verified_channel_ids)} Jamaican channels\")\n",
        "else:\n",
        "    print(\"‚ùå No channel IDs found\")\n",
        "    verified_channel_ids = []\n",
        "\n",
        "# Collect videos from verified Jamaican channels\n",
        "all_channel_videos = []\n",
        "if verified_channel_ids:\n",
        "    for i, cid in enumerate(verified_channel_ids):\n",
        "        print(f\"üìπ Processing channel {i+1}/{len(verified_channel_ids)}: {cid}\")\n",
        "\n",
        "        uploads = get_channel_uploads(cid, max_results=30, max_pages=8)  # Your original limits\n",
        "\n",
        "        video_ids = []\n",
        "        for item in uploads:\n",
        "            try:\n",
        "                if (\"snippet\" in item and\n",
        "                    \"resourceId\" in item[\"snippet\"] and\n",
        "                    \"videoId\" in item[\"snippet\"][\"resourceId\"]):\n",
        "                    video_ids.append(item[\"snippet\"][\"resourceId\"][\"videoId\"])\n",
        "            except (KeyError, TypeError):\n",
        "                continue\n",
        "\n",
        "        # Get video details if we have valid IDs\n",
        "        if video_ids:\n",
        "            details = get_video_details(video_ids)\n",
        "            if details:\n",
        "                all_channel_videos.extend(details)\n",
        "                print(f\"  ‚úÖ Collected {len(details)} videos\")\n",
        "            else:\n",
        "                print(f\"  ‚ö† No video details retrieved\")\n",
        "        else:\n",
        "            print(f\"  ‚ö† No video IDs found\")\n",
        "\n",
        "        # Small delay between channels\n",
        "        time.sleep(1)\n",
        "\n",
        "# Parse channel videos\n",
        "df_channel_videos = parse_videos(all_channel_videos)\n",
        "\n",
        "# Filter by date if we have data\n",
        "if not df_channel_videos.empty:\n",
        "    df_channel_videos['publish_date'] = pd.to_datetime(df_channel_videos['publish_date'])\n",
        "    initial_count = len(df_channel_videos)\n",
        "    df_channel_videos = df_channel_videos[df_channel_videos['publish_date'] >= '2019-01-01']\n",
        "    final_count = len(df_channel_videos)\n",
        "    print(f\"‚úÖ Channel videos: {final_count} (filtered from {initial_count} total)\")\n",
        "else:\n",
        "    print(\"‚ùå No channel videos found for the specified criteria\")"
      ],
      "metadata": {
        "id": "bxdhc89ylBiK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3d61400-6f25-41eb-83fe-e672c32ea1a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Step 10a: Collecting videos from Jamaican channels...\n",
            "Found 50 channel IDs to process\n",
            "üîç Filtering channels by country (JM)...\n",
            "Verified 2 Jamaican channels\n",
            "üìπ Processing channel 1/2: UCEL9_gFV9YRasbbsu5v8Ynw\n",
            "  ‚úÖ Collected 240 videos\n",
            "üìπ Processing channel 2/2: UC1c6TamEwT02iC4LKv9WGlQ\n",
            "  ‚úÖ Collected 179 videos\n",
            "‚úÖ Channel videos: 419 (filtered from 419 total)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10b: Videos from Keyword Search"
      ],
      "metadata": {
        "id": "5YCxj67xV6EJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîç Step 10b: Collecting videos from keyword search...\")\n",
        "\n",
        "search_results = search_videos(\"Jamaica\", max_results=20, max_pages=90)  # Your original limits\n",
        "\n",
        "# Enhanced video ID extraction with validation\n",
        "search_video_ids = []\n",
        "for item in search_results:\n",
        "    try:\n",
        "        if (isinstance(item, dict) and\n",
        "            isinstance(item.get(\"id\"), dict) and\n",
        "            item[\"id\"].get(\"videoId\")):\n",
        "            search_video_ids.append(item[\"id\"][\"videoId\"])\n",
        "    except (KeyError, TypeError):\n",
        "        continue\n",
        "\n",
        "# Remove any None or empty values\n",
        "search_video_ids = [vid_id for vid_id in search_video_ids if vid_id and isinstance(vid_id, str)]\n",
        "\n",
        "print(f\"Found {len(search_video_ids)} video IDs from keyword search\")\n",
        "\n",
        "# Initialize empty DataFrame\n",
        "df_search_videos = pd.DataFrame()\n",
        "\n",
        "# Get video details if we have IDs\n",
        "if search_video_ids:\n",
        "    print(\"üìπ Getting details for search videos...\")\n",
        "    search_details = get_video_details(search_video_ids)\n",
        "    if search_details:\n",
        "        df_search_videos = parse_videos(search_details)\n",
        "        print(f\"‚úÖ Search videos: {len(df_search_videos)}\")\n",
        "    else:\n",
        "        print(\"‚ùå No search video details retrieved\")\n",
        "else:\n",
        "    print(\"‚ùå No search videos found for the specified criteria\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRTNSpX3V8f2",
        "outputId": "d87972e4-88f6-44db-b89f-0c68d10ba12b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîç Step 10b: Collecting videos from keyword search...\n",
            "Found 598 video IDs from keyword search\n",
            "üìπ Getting details for search videos...\n",
            "‚úÖ Search videos: 598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10c: Combine & Deduplicate"
      ],
      "metadata": {
        "id": "y_j6oNi4V_a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüîÑ Step 10c: Combining and deduplicating data...\")\n",
        "\n",
        "# Combine dataframes\n",
        "dataframes_to_combine = []\n",
        "if not df_channel_videos.empty:\n",
        "    df_channel_videos['source'] = 'channel_search'\n",
        "    dataframes_to_combine.append(df_channel_videos)\n",
        "    print(f\"  Channel videos: {len(df_channel_videos)}\")\n",
        "\n",
        "if not df_search_videos.empty:\n",
        "    df_search_videos['source'] = 'keyword_search'\n",
        "    dataframes_to_combine.append(df_search_videos)\n",
        "    print(f\"  Search videos: {len(df_search_videos)}\")\n",
        "\n",
        "if dataframes_to_combine:\n",
        "    df_videos_combined = pd.concat(dataframes_to_combine, ignore_index=True)\n",
        "\n",
        "    # Show deduplication stats\n",
        "    before_dedup = len(df_videos_combined)\n",
        "    df_videos_combined.drop_duplicates(subset=\"video_id\", inplace=True)\n",
        "    after_dedup = len(df_videos_combined)\n",
        "\n",
        "    print(f\"‚úÖ Combined: {after_dedup} unique videos (removed {before_dedup - after_dedup} duplicates)\")\n",
        "else:\n",
        "    print(\"‚ùå No data to combine\")\n",
        "    df_videos_combined = pd.DataFrame()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beAA8bPrWDnq",
        "outputId": "77652b08-679f-439f-b363-c630ca7111b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Step 10c: Combining and deduplicating data...\n",
            "  Channel videos: 419\n",
            "  Search videos: 598\n",
            "‚úÖ Combined: 901 unique videos (removed 116 duplicates)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10d: Get Channel Stats & Merge"
      ],
      "metadata": {
        "id": "L2Mp1kSLWJ-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìä Step 10d: Getting channel statistics and merging...\")\n",
        "\n",
        "if not df_videos_combined.empty:\n",
        "    unique_channels = df_videos_combined[\"channel_id\"].unique().tolist()\n",
        "    print(f\"Getting stats for {len(unique_channels)} unique channels...\")\n",
        "\n",
        "    df_channels = get_channel_statistics(unique_channels)\n",
        "\n",
        "    if not df_channels.empty:\n",
        "        # Merge with channel stats\n",
        "        df_final = df_videos_combined.merge(df_channels, on=\"channel_id\", how=\"left\")\n",
        "\n",
        "        # Ensure 'publish_date' is in datetime format after merge\n",
        "        try:\n",
        "            df_final['publish_date'] = pd.to_datetime(df_final['publish_date'], errors='coerce')\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not convert 'publish_date' to datetime after merge: {e}\")\n",
        "\n",
        "        # Show merge results\n",
        "        channels_with_stats = df_final['subscriber_count'].notna().sum()\n",
        "        print(f\"‚úÖ Merged channel stats: {channels_with_stats}/{len(df_final)} videos have channel data\")\n",
        "\n",
        "        # Display summary statistics\n",
        "        print(f\"\\nüìà Final Dataset Summary:\")\n",
        "        print(f\"  Total videos: {len(df_final):,}\")\n",
        "        print(f\"  Unique channels: {df_final['channel_id'].nunique():,}\")\n",
        "        print(f\"  Total views: {df_final['views'].sum():,}\")\n",
        "\n",
        "        # Add checks for min/max date before printing\n",
        "        if pd.api.types.is_datetime64_any_dtype(df_final['publish_date']):\n",
        "             print(f\"  Date range: {df_final['publish_date'].min()} to {df_final['publish_date'].max()}\")\n",
        "        else:\n",
        "             print(\"  Date range: Could not determine due to mixed data types in 'publish_date'\")\n",
        "\n",
        "        print(f\"  Channels with country data: {df_final['channel_country'].notna().sum():,}\")\n",
        "\n",
        "    else:\n",
        "        print(\"‚ö† No channel statistics retrieved, using video data only\")\n",
        "        df_final = df_videos_combined\n",
        "else:\n",
        "    print(\"‚ùå No combined data to process\")\n",
        "    df_final = pd.DataFrame()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK2-pLoJWOHp",
        "outputId": "f923bf4e-fff9-4ea8-f15e-2de8f60c2ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Step 10d: Getting channel statistics and merging...\n",
            "Getting stats for 303 unique channels...\n",
            "‚úÖ Merged channel stats: 901/901 videos have channel data\n",
            "\n",
            "üìà Final Dataset Summary:\n",
            "  Total videos: 901\n",
            "  Unique channels: 303\n",
            "  Total views: 1,770,210,203\n",
            "  Date range: 2019-08-16 13:29:41+00:00 to 2025-08-27 04:52:51+00:00\n",
            "  Channels with country data: 901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Save to CSV/Excel"
      ],
      "metadata": {
        "id": "NHSj4rHbMiLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüíæ Step 11: Saving data...\")\n",
        "\n",
        "if not df_final.empty:\n",
        "    try:\n",
        "        # Save as CSV\n",
        "        csv_filename = f\"jamaican_youtube_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
        "        df_final.to_csv(csv_filename, index=False)\n",
        "        print(f\"‚úÖ Saved CSV: {csv_filename}\")\n",
        "\n",
        "        # Save as Excel\n",
        "        excel_filename = f\"jamaican_youtube_data_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.xlsx\"\n",
        "        df_final.to_excel(excel_filename, index=False)\n",
        "        print(f\"‚úÖ Saved Excel: {excel_filename}\")\n",
        "\n",
        "        print(f\"\\nüéâ Data collection complete!\")\n",
        "        print(f\"Final dataset: {len(df_final)} videos from {df_final['channel_id'].nunique()} channels\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error saving files: {e}\")\n",
        "        print(\"Data is still available in df_final variable\")\n",
        "else:\n",
        "    print(\"‚ùå No data to save\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"COLLECTION SUMMARY\")\n",
        "print(\"=\"*50)\n",
        "if 'df_final' in locals() and not df_final.empty:\n",
        "    print(f\"‚úÖ SUCCESS: {len(df_final)} videos collected\")\n",
        "    print(f\"üì∫ Channels: {df_final['channel_id'].nunique()}\")\n",
        "    print(f\"üëÄ Total Views: {df_final['views'].sum():,}\")\n",
        "    if 'source' in df_final.columns:\n",
        "        source_counts = df_final['source'].value_counts()\n",
        "        for source, count in source_counts.items():\n",
        "            print(f\"üìä {source}: {count} videos\")\n",
        "else:\n",
        "    print(\"‚ùå No data collected - check API key and network connection\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih_tbQQXIULv",
        "outputId": "58ecce2c-5969-40a2-8f90-68bdc78c967f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ Step 11: Saving data...\n",
            "‚úÖ Saved CSV: jamaican_youtube_data_20250827_0635.csv\n",
            "‚ùå Error saving files: Excel does not support datetimes with timezones. Please ensure that datetimes are timezone unaware before writing to Excel.\n",
            "Data is still available in df_final variable\n",
            "\n",
            "==================================================\n",
            "COLLECTION SUMMARY\n",
            "==================================================\n",
            "‚úÖ SUCCESS: 901 videos collected\n",
            "üì∫ Channels: 303\n",
            "üëÄ Total Views: 1,770,210,203\n",
            "üìä keyword_search: 482 videos\n",
            "üìä channel_search: 419 videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save as CSV\n",
        "df_final.to_csv(\"jamaican_youtube_data_20250827_0635.csv\", index=False)\n",
        "\n",
        "# Save as Excel\n",
        "#df_final.to_excel(\"jamaican_youtube_data.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "FEX45fZtMmlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the csv file"
      ],
      "metadata": {
        "id": "WXvB7k1oMna_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"jamaican_youtube_data_20250827_0635.csv\")\n"
      ],
      "metadata": {
        "id": "NvSrLbEFMsL1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "82cebec3-1f88-429d-cfae-348397fb9c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6add4da1-5cd3-4b62-b95d-f4fc0d4c8a09\", \"jamaican_youtube_data_20250827_0635.csv\", 1791519)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}